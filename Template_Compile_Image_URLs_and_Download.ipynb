{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMWpznwLBtbrj8u5LN9v60",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-donat/Useful_Templates/blob/main/Template_Compile_Image_URLs_and_Download.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Template created by Annalisa Donat"
      ],
      "metadata": {
        "id": "2asEtvUIzil9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a template that can be adapted to perform the following tasks:\n",
        "1. (Executes concurrently with step 2) Scrape the html for a website (or websites) for image urls matching html-related criteria.\n",
        "2. Create a csv file containing the image url, an assigned id, and any other data pertaining to the image.\n",
        "3. Download the images.\n",
        "\n"
      ],
      "metadata": {
        "id": "KA8Ux3DRgBZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parts 1 and 2: Compile and Log Image URLs"
      ],
      "metadata": {
        "id": "pRBxQ2LgikuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "088yyNClizPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import *\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0aheJkgUiyWn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ONLY RUN IF LOGGING TIME PULLED\n",
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "1vvCkuC28Aij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Functions"
      ],
      "metadata": {
        "id": "sGHhAi7vjTDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wrapped_find_first(pattern: str | re.Pattern, full_str: str) -> str:\n",
        "  '''Returns first instance of pattern found if pattern found in full_str,\n",
        "  else returns empty string'''\n",
        "  try:\n",
        "    return re.findall(pattern, full_str)[0]\n",
        "  # If pattern is not found in full_str, it will raise an IndexError\n",
        "  except IndexError:\n",
        "    return ''\n",
        "\n",
        "\n",
        "def wrapped_find_all(pattern: str | re.Pattern, full_str: str) -> str:\n",
        "  '''Returns first instance of pattern found if pattern found in full_str,\n",
        "  else returns empty list'''\n",
        "  try:\n",
        "    return re.findall(pattern, full_str)\n",
        "  # If pattern is not found in full_str, it will raise an IndexError\n",
        "  except IndexError:\n",
        "    return []"
      ],
      "metadata": {
        "id": "I_bR3aMVkt_R"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes on Regex**<br>\n",
        "To view the html of a website in chrome, control-click anywhere and select \"view page source\" on the drop-down menu that appears.\n",
        "\n",
        "Tool for debugging regex: https://regex101.com/. Remember to select Python under flavor menu on the left.<br><br> example regex: \"first_part(.+?)last_part\""
      ],
      "metadata": {
        "id": "SgEQvg6TlMkk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUMkH15Uf4_a"
      },
      "outputs": [],
      "source": [
        "def placeholder_id_generator():\n",
        "  # ADD YOUR CODE HERE\n",
        "  pass\n",
        "\n",
        "def parse_webpage(webpage_soup: BeautifulSoup | str) -> List[List[str]]:\n",
        "  photo_urls = wrapped_find_all('PHOTO_URL_REGEX_HERE', str(webpage_soup))\n",
        "  photo_ids = placeholder_id_generator()\n",
        "  # OPTIONAL, PARSE OTHER INFO:\n",
        "  info_1 = wrapped_find_all('INFO1_REGEX_HERE', str(webpage_soup))\n",
        "  info_2 = wrapped_find_all('INFO2_REGEX_HERE', str(webpage_soup))\n",
        "  # ADD CODE HERE TO CHECK THAT ALL LISTS ABOVE HAVE SAME LENGTH:\n",
        "  return [photo_ids, photo_urls, info_1, info_2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def iterate_through_search_results(results_url: str, n_pages: int = 1,\n",
        "                    pages_offset = 0,\n",
        "                    max_n_pages_scrape: int = 100):\n",
        "  \"\"\"\n",
        "  Inputs\n",
        "  ------\n",
        "  results_url: str\n",
        "  n_pages >= 1\n",
        "  pages_offset >= 0\n",
        "  max_n_pages_scrape\n",
        "    if max_pages_scape > n_pages, then max_n_pages_scrape == num pages pulled\n",
        "    if n_pages <= max_n_pages_scrape, then n_pages == num pages pulled\n",
        "  \"\"\"\n",
        "  i = 0\n",
        "  results_dict = {\"image_ids\": [], \"image_urls\": [], \"info_1\": [], \"info_2\": []}\n",
        "  # CAUTION: MUST BE SAME ORDER THAT parse_webpage() RETURNS IN\n",
        "  results_vars = [\"image_ids\", \"image_urls\", \"info_1\", \"info_2\"]\n",
        "\n",
        "  while i < min(n_pages, max_n_pages_scrape):\n",
        "    print(\".  \", i)\n",
        "    offset = \"?start=%d&tab=\" % ((i+pages_offset) * 30)\n",
        "    page_url = results_url.replace(\"?tab=\", offset)\n",
        "    page_html = requests.get(page_url)\n",
        "    page_soup = BeautifulSoup(page_html.text, \"html.parser\")\n",
        "    metadata = parse_webpage(page_soup)\n",
        "    for var_ind, var_name in enumerate(results_vars):\n",
        "      results_dict[var_name] += metadata[var_ind]\n",
        "    i += 1\n",
        "\n",
        "  search_results_df = pd.DataFrame.from_dict(results_dict)\n",
        "  # could move to make more granular, or simply delete:\n",
        "  search_results_df[\"date_logged\"] = datetime.now()\n",
        "  return search_results_df"
      ],
      "metadata": {
        "id": "JJbF8Z_wyowa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_soup = BeautifulSoup(requests.get(\n",
        "    \"https://www.vivino.com/US-NY/en/batasiolo-barolo/w/77756?year=2012\",\n",
        "    headers={\"User-Agent\": \"Mozilla/5.0\"}).text, \"html.parser\")"
      ],
      "metadata": {
        "id": "3iRauIxTkJ7L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile and Log"
      ],
      "metadata": {
        "id": "BvxhIpY93QTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "don't forget to use .to_csv()"
      ],
      "metadata": {
        "id": "Oxg35khS3UTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Download Photos"
      ],
      "metadata": {
        "id": "avaT4Yz13bNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries\n",
        "(assumes libraries needed for parts 1 and 2 have been imported)"
      ],
      "metadata": {
        "id": "COx4m_Rj40uX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from os import mkdir"
      ],
      "metadata": {
        "id": "YbeDO9iL4-_E"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Functions"
      ],
      "metadata": {
        "id": "7Y0CSOh85VY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_template = \"URL_TEMPLATE_HERE\"\n",
        "\n",
        "\n",
        "def download_image_opt1(image_id: str, folder_root: str):\n",
        "  \"\"\"\n",
        "  ex. url_template = 'https://s3-media0.fl.yelpcdn.com/bphoto/photo_id/258s.jpg'\n",
        "  \"\"\"\n",
        "  img_content = requests.get(\n",
        "    url_template.replace(\"photo_id\", image_id)).content\n",
        "  with open(\"/content/%s/%s_%s.jpg\" % (\n",
        "      folder_root, folder_root, image_id), \"wb\") as handler:\n",
        "    handler.write(img_content)\n",
        "\n",
        "\n",
        "def download_image_opt2(image_url: str, image_id: str, folder_root: str):\n",
        "  img_content = requests.get(image_url).content\n",
        "  with open(\"/content/%s/%s_%s.jpg\" % (\n",
        "      folder_root, folder_root, image_id), \"wb\") as handler:\n",
        "    handler.write(img_content)"
      ],
      "metadata": {
        "id": "DvSJchXg52NN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_image(photo_id: str, orig_root_folder: str, dest_root_folder: str,\n",
        "                 new_width: int = 80, new_height: int = 80):\n",
        "  img_orig = Image.open(\"/content/%s/%s_%s.jpg\" % (\n",
        "      orig_root_folder, orig_root_folder, photo_id))\n",
        "\n",
        "  resized_img = img_orig.resize((new_width, new_height))\n",
        "\n",
        "  resized_img.save(\"/content/%s/%s_%s.jpg\" % (\n",
        "      dest_root_folder, dest_root_folder, photo_id))"
      ],
      "metadata": {
        "id": "ihUUciN15ZCh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Images"
      ],
      "metadata": {
        "id": "zV2jeUDD62gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EXAMPLE\n",
        "'''\n",
        "image_pull_dates = {}\n",
        "for x in my_df[\"image_id\"]:\n",
        "  download_image_opt1(x, \"my_folder_root\")\n",
        "  image_pull_dates[x] = datetime.now()\n",
        "  # IF LOGGING PULL TIMES, THEN SAVE THIS DATA SOMEWHERE\n",
        "  print(x)'''"
      ],
      "metadata": {
        "id": "k-691_Jb66V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXAMPLE\n",
        "!zip -r 'my_folder_root.zip' '/content/my_folder_root'\n",
        "# DON'T FORGET TO DOWNLOAD TO DISC OR UPLOAD TO DRIVE"
      ],
      "metadata": {
        "id": "yHIt01tt7UI4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}